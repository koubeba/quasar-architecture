{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marking org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.5 for download\n",
      "Obtained 12 files\n"
     ]
    }
   ],
   "source": [
    "%AddDeps org.apache.spark spark-sql-kafka-0-10_2.11 2.4.5 --transitive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the connector. Note the _--transitive_ flag- it is necessary in order to download Kafka utils etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.DataFrame\n",
    "import org.apache.spark.sql.types._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark = org.apache.spark.sql.SparkSession@7a546bb9\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@7a546bb9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession.builder().appName(\"MessageProcessor\")\n",
    "            .master(\"spark://spark:7077\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain dataframes from Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataframe = [key: binary, value: binary ... 5 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[key: binary, value: binary ... 5 more fields]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dataframe = spark\n",
    "    .readStream\n",
    "    .format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka1:29092\")\n",
    "    .option(\"subscribe\", \"Spectra\")\n",
    "    .option(\"startingOffsets\", \"earliest\")\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "output = org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@1658cbf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@1658cbf"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val output = dataframe\n",
    "                    .selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\")\n",
    "                    .as[(String, String)]\n",
    "                    .writeStream\n",
    "                    .outputMode(\"append\")\n",
    "                    .format(\"memory\")\n",
    "                    .queryName(\"spectra\")\n",
    "                    .start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformacje Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spectra = [key: string, value: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[key: string, value: string]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spectra = spark.sql(\"select * from spectra\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Odczytuję schemat kolumny z wartościami. Jest on w JSON, ale zamienię go na osobne kolumny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "explode_JSON: (table: org.apache.spark.sql.DataFrame, column_name: String)org.apache.spark.sql.DataFrame\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def explode_JSON(table: DataFrame, column_name: String): DataFrame = {\n",
    "    val JSONschema: StructType = spark.read.json(table.select(column_name).as[String]).schema\n",
    "    table.withColumn(\"JSON\", from_json(col(column_name), JSONschema)).select(\"JSON.*\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kolumna z kluczem nie jest potrzebna- służy ona do oznaczania wiadomości podczas przesyłu przez Kafkę i nie stanowi części danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformedDF = [continuum: string, dec: string ... 12 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[continuum: string, dec: string ... 12 more fields]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val transformedDF = explode_JSON(spectra, \"value\").select(\"dataRow.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((continuum,StringType), (dec,StringType), (fiber,StringType), (mjd,StringType), (name,StringType), (plate,StringType), (ra,StringType), (size,StringType), (spectraSetOID,StringType), (spectrum,StringType), (subtype,StringType), (type,StringType), (z,StringType), (zerr,StringType))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformedDF.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-----+-----+--------------------+-----+---------+----+--------------------+\n",
      "|           continuum|        dec|fiber|  mjd|                name|plate|       ra|size|       spectraSetOID|\n",
      "+--------------------+-----------+-----+-----+--------------------+-----+---------+----+--------------------+\n",
      "|[1.36860629060082...|-0.98491332|    3|51630|SDSS J094736.55-0...|  266|146.90229|3819|ObjectId(5cdd4ad3...|\n",
      "|                null|       null| null| null|                null| null|     null|null|                    |\n",
      "+--------------------+-----------+-----+-----+--------------------+-----+---------+----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformedDF.select(\"continuum\", \"dec\", \"fiber\", \"mjd\", \"name\", \"plate\", \"ra\", \"size\", \"spectraSetOID\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+------------------+--------------------+\n",
      "|            spectrum|             subtype|  type|                 z|                zerr|\n",
      "+--------------------+--------------------+------+------------------+--------------------+\n",
      "|[-3.1290216943920...|BROADLINE        ...|QSO   |0.6524170637130737|8.855115447659045...|\n",
      "|                null|                null|  null|              null|                null|\n",
      "+--------------------+--------------------+------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformedDF.select(\"spectrum\", \"subtype\", \"type\", \"z\", \"zerr\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kolumny ze wszystkimi wartościami nullowymi na pewno są błędem w przesyłaniu danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-----+-----+--------------------+-----+---------+----+--------------------+--------------------+--------------------+------+------------------+--------------------+\n",
      "|           continuum|        dec|fiber|  mjd|                name|plate|       ra|size|       spectraSetOID|            spectrum|             subtype|  type|                 z|                zerr|\n",
      "+--------------------+-----------+-----+-----+--------------------+-----+---------+----+--------------------+--------------------+--------------------+------+------------------+--------------------+\n",
      "|[1.36860629060082...|-0.98491332|    3|51630|SDSS J094736.55-0...|  266|146.90229|3819|ObjectId(5cdd4ad3...|[-3.1290216943920...|BROADLINE        ...|QSO   |0.6524170637130737|8.855115447659045...|\n",
      "+--------------------+-----------+-----+-----+--------------------+-----+---------+----+--------------------+--------------------+--------------------+------+------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "droppedDF = [continuum: string, dec: string ... 12 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[continuum: string, dec: string ... 12 more fields]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val droppedDF = transformedDF.na.drop(\"all\", transformedDF.drop(\"spectraSetOID\").columns)\n",
    "droppedDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wszystkie typy są reprezentowane jako łańcuchy- niektóre kolumny trzeba przekonwertować do liczb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((continuum,StringType), (dec,StringType), (fiber,StringType), (mjd,StringType), (name,StringType), (plate,StringType), (ra,StringType), (size,StringType), (spectraSetOID,StringType), (spectrum,StringType), (subtype,StringType), (type,StringType), (z,StringType), (zerr,StringType))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "droppedDF.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stringToArray = UserDefinedFunction(<function1>,ArrayType(StringType,true),Some(List(StringType)))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "UserDefinedFunction(<function1>,ArrayType(StringType,true),Some(List(StringType)))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val stringToArray = udf((b: String) => b.substring(1, b.length()-1).split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trimString = UserDefinedFunction(<function1>,StringType,Some(List(StringType)))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "UserDefinedFunction(<function1>,StringType,Some(List(StringType)))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val trimString = udf((b: String) => b.trim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "castDF = [continuum: array<double>, dec: double ... 12 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[continuum: array<double>, dec: double ... 12 more fields]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val castDF = droppedDF\n",
    "                .withColumn(\"continuum\", stringToArray(col(\"continuum\")).cast(ArrayType(DoubleType, true)))\n",
    "                .withColumn(\"dec\", col(\"dec\").cast(DoubleType))\n",
    "                .withColumn(\"fiber\", col(\"fiber\").cast(LongType))\n",
    "                .withColumn(\"mjd\", col(\"mjd\").cast(LongType))\n",
    "                .withColumn(\"plate\", col(\"plate\").cast(LongType))\n",
    "                .withColumn(\"ra\", col(\"ra\").cast(DoubleType))\n",
    "                .withColumn(\"size\", col(\"size\").cast(LongType))\n",
    "                .withColumn(\"spectrum\", stringToArray(col(\"spectrum\")).cast(ArrayType(DoubleType, true)))\n",
    "                .withColumn(\"subtype\", trimString(col(\"subtype\")))\n",
    "                .withColumn(\"type\", trimString(col(\"type\")))\n",
    "                .withColumn(\"z\", col(\"z\").cast(DoubleType))\n",
    "                .withColumn(\"zerr\", col(\"zerr\").cast(DoubleType))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-----+-----+--------------------+-----+---------+----+--------------------+--------------------+---------+----+------------------+--------------------+\n",
      "|           continuum|        dec|fiber|  mjd|                name|plate|       ra|size|       spectraSetOID|            spectrum|  subtype|type|                 z|                zerr|\n",
      "+--------------------+-----------+-----+-----+--------------------+-----+---------+----+--------------------+--------------------+---------+----+------------------+--------------------+\n",
      "|[1.36860629060082...|-0.98491332|    3|51630|SDSS J094736.55-0...|  266|146.90229|3819|ObjectId(5cdd4ad3...|[-3.1290216943920...|BROADLINE| QSO|0.6524170637130737|8.855115447659045E-5|\n",
      "+--------------------+-----------+-----+-----+--------------------+-----+---------+----+--------------------+--------------------+---------+----+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "castDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((continuum,ArrayType(DoubleType,true)), (dec,DoubleType), (fiber,LongType), (mjd,LongType), (name,StringType), (plate,LongType), (ra,DoubleType), (size,LongType), (spectraSetOID,StringType), (spectrum,ArrayType(DoubleType,true)), (subtype,StringType), (type,StringType), (z,DoubleType), (zerr,DoubleType))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "castDF.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takie dane będą już gotowe do analizy. Aby ten proces mógłbyć na bieżąco stosowany dla wszystkich przychodzących danych, dobrze będzie go umieścić w skrypcie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
