{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marking org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.5 for download\n",
      "Obtained 12 files\n"
     ]
    }
   ],
   "source": [
    "%AddDeps org.apache.spark spark-sql-kafka-0-10_2.11 2.4.5 --transitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.DataFrame\n",
    "import org.apache.spark.sql.types._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark = org.apache.spark.sql.SparkSession@651641ff\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@651641ff"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession.builder().appName(\"StreamingModel\")\n",
    "            .master(\"spark://spark:7077\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataframe = [key: binary, value: binary ... 5 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[key: binary, value: binary ... 5 more fields]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dataframe = spark\n",
    "    .readStream\n",
    "    .format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka1:29092\")\n",
    "    .option(\"subscribe\", \"Spectra\")\n",
    "    .option(\"startingOffsets\", \"earliest\")\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "output = org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@5bf1623\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@5bf1623"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val output = dataframe\n",
    "            .selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\")\n",
    "            .as[(String, String)]\n",
    "            .writeStream\n",
    "            .outputMode(\"append\")\n",
    "            .format(\"memory\")\n",
    "            .queryName(\"spectra\")\n",
    "            .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stringToArray = UserDefinedFunction(<function1>,ArrayType(StringType,true),Some(List(StringType)))\n",
       "trimString = UserDefinedFunction(<function1>,StringType,Some(List(StringType)))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "explode_JSON: (table: org.apache.spark.sql.DataFrame, column_name: String)org.apache.spark.sql.DataFrame\n",
       "process_dataframe: (df: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "UserDefinedFunction(<function1>,StringType,Some(List(StringType)))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def explode_JSON(table: DataFrame, column_name: String): DataFrame = {\n",
    "    val JSONschema: StructType = spark.read.json(table.select(column_name).as[String]).schema\n",
    "    table.withColumn(\"JSON\", from_json(col(column_name), JSONschema)).select(\"JSON.*\")\n",
    "}\n",
    "\n",
    "val stringToArray = udf((b: String) => b.substring(1, b.length()-1).split(\",\"))\n",
    "\n",
    "val trimString = udf((b: String) => b.trim())\n",
    "\n",
    "def process_dataframe(df: DataFrame) = {\n",
    "    val exploded = explode_JSON(df, \"value\").select(\"dataRow.*\").drop(\"spectraSetOID\")\n",
    "    exploded.na.drop(\"all\")\n",
    "                .withColumn(\"continuum\", stringToArray(col(\"continuum\")).cast(ArrayType(DoubleType, true)))\n",
    "                .withColumn(\"dec\", col(\"dec\").cast(DoubleType))\n",
    "                .withColumn(\"fiber\", col(\"fiber\").cast(LongType))\n",
    "                .withColumn(\"mjd\", col(\"mjd\").cast(LongType))\n",
    "                .withColumn(\"plate\", col(\"plate\").cast(LongType))\n",
    "                .withColumn(\"ra\", col(\"ra\").cast(DoubleType))\n",
    "                .withColumn(\"size\", col(\"size\").cast(LongType))\n",
    "                .withColumn(\"spectrum\", stringToArray(col(\"spectrum\")).cast(ArrayType(DoubleType, true)))\n",
    "                .withColumn(\"subtype\", trimString(col(\"subtype\")))\n",
    "                .withColumn(\"type\", trimString(col(\"type\")))\n",
    "                .withColumn(\"z\", col(\"z\").cast(DoubleType))\n",
    "                .withColumn(\"zerr\", col(\"zerr\").cast(DoubleType))\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spectra = [continuum: array<double>, dec: double ... 11 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[continuum: array<double>, dec: double ... 11 more fields]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spectra = process_dataframe(spark.sql(\"select * from spectra\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trzeba rozdzieliÄ‡ tablice spectrum i continuum na osobne kolumny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "continuum_size = [4096]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[4096]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val continuum_size = spectra.select(size($\"continuum\")).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spectrum_size = [4096]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[4096]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spectrum_size = spectra.select(size($\"spectrum\")).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "columns = Vector(spectrum[0], spectrum[1], spectrum[2], spectrum[3], spectrum[4], spectrum[5], spectrum[6], spectrum[7], spectrum[8], spectrum[9], spectrum[10], spectrum[11], spectrum[12], spectrum[13], spectrum[14], spectrum[15], spectrum[16], spectrum[17], spectrum[18], spectrum[19], spectrum[20], spectrum[21], spectrum[22], spectrum[23], spectrum[24], spectrum[25], spectrum[26], spectrum[27], spectrum[28], spectrum[29], spectrum[30], spectrum[31], spectrum[32], spectrum[33], spectrum[34], spectrum[35], spectrum[36], spectrum[37], spectrum[38], spectrum[39], spectrum[40], spectrum[41], spectrum[42], spectrum[43], spectrum[44], spectrum[45], spectrum[46], spectrum[47], spectrum[48], spectrum[49], spectrum[50], spectrum...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Vector(spectrum[0], spectrum[1], spectrum[2], spectrum[3], spectrum[4], spectrum[5], spectrum[6], spectrum[7], spectrum[8], spectrum[9], spectrum[10], spectrum[11], spectrum[12], spectrum[13], spectrum[14], spectrum[15], spectrum[16], spectrum[17], spectrum[18], spectrum[19], spectrum[20], spectrum[21], spectrum[22], spectrum[23], spectrum[24], spectrum[25], spectrum[26], spectrum[27], spectrum[28], spectrum[29], spectrum[30], spectrum[31], spectrum[32], spectrum[33], spectrum[34], spectrum[35], spectrum[36], spectrum[37], spectrum[38], spectrum[39], spectrum[40], spectrum[41], spectrum[42], spectrum[43], spectrum[44], spectrum[45], spectrum[46], spectrum[47], spectrum[48], spectrum[49], spectrum[50], spectrum..."
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val columns = (0 until 4096).map(r => spectra.col(\"spectrum\").getItem(r)) ++\n",
    "              (0 until 4096).map(r => spectra.col(\"continuum\").getItem(r)) ++\n",
    "              spectra.drop(\"spectrum\", \"continuum\").columns.map(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "exploded_spectra = [spectrum[0]: double, spectrum[1]: double ... 8201 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[spectrum[0]: double, spectrum[1]: double ... 8201 more fields]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val exploded_spectra = spectra.select(columns: _*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
